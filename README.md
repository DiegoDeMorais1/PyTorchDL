# PyTorchDL

Rápida descrição do objetivo de fazer esse projeto
:placard: Vitrine.Dev 	
:sparkles: Nome 	Deep learning with Pythorch
:label: Tecnologias 	python, google cobab, pandas pythorch,
:rocket: URL 	https://cursos.alura.com.br/course/pln-deep-learning

(https://github.com/DiegoDeMorais1/PyTorchDL/blob/main/wine1.png) 

O machine learning tradicional tem duas etapas. A etapa de extração de características, onde o programador diz quais características são relevantes. No caso do cachorro eu posso procurar por pontas de orelha, por círculos, equivalente aos olhos. E aí eu vou treinar um modelo de classificação provavelmente, que não precisa ser rede neural, pode ser qualquer outro modelo, que vai me dizer que isso é um cachorro.

Só que o que eu faço com o deep learning é as duas coisas ao mesmo tempo, eu crio uma rede profunda que vai aprender características e treinar um modelo de inferência ao mesmo tempo. Portando, é isso que é o deep learning: o aprendizado de características para realizar inferências.Deep learning, porque a modelagem hierárquica, o aprendizado profundo permite a construção de modelos mais robustos e mais complexos.

Pytorch é uma biblioteca Python para computação científica. Inclusive é uma das mais utilizadas para pesquisa científica quando se trata de deep learning. O slogan deles é “Da pesquisa para produção”.

A Pytorch é capaz de realizar cálculos utilizando tensores. Tensores podem ser entendidos como vetores n-dimensionais. A vantagem dos tensores da Pytorch é que eles podem ser utilizados tanto em CPUs quanto em GPUs e isso acelera os processos computacionais relacionados ao deep learning.

Só relembrando o teorema da aproximação universal, ele vai fechar o potencial, ele vai definir o potencial de uma rede neural, que uma rede neural com apenas uma camada escondida é suficiente para representar qualquer função. É aí que está o “Q” da coisa. Ela vai aprender as características, vai transformar o espaço da sua entrada, para que a última camada consiga separar isso de forma linear. 
